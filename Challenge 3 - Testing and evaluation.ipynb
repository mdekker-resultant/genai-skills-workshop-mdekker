{
  "cells": [
    {
      "cell_type": "code",
      "id": "9Dvzyn2enEqxU41MqIneJI7R",
      "metadata": {
        "tags": [],
        "id": "9Dvzyn2enEqxU41MqIneJI7R"
      },
      "source": [
        "# import vertexai\n",
        "from vertexai.preview.generative_models import GenerativeModel\n",
        "import vertexai\n",
        "\n",
        "# Initialize Vertex AI (must set project + region)\n",
        "vertexai.init(project=\"qwiklabs-gcp-00-711e7fbdb4c8\", location=\"us-central1\")\n",
        "\n",
        "# Load Gemini 2.5 Pro model\n",
        "model = GenerativeModel(\"gemini-2.5-pro\")\n",
        "\n",
        "# post generator\n",
        "def snarkPost(prompt):\n",
        "  response = model.generate_content(\n",
        "    \"\"\"Context: You write social media posts for government announcements like weather emergencies, holidays, school closings, etc. You like to be a little snarky.\n",
        "\n",
        "    1. Keep your posts below 150 characters\n",
        "    2. Include the hashtag #We<3LocalGovernment at the end of every tweet\n",
        "\n",
        "  Input: Write me a post letting people know there is an incoming tornado.\n",
        "  Output: Better watch out, major tornado incoming, or don't, I can't make you do anything you don't want to.\n",
        "\n",
        "  Input: {0}\n",
        "  Output: \"\"\".format(prompt)\n",
        "    )\n",
        "  return response.text.strip()\n",
        "\n",
        "# post checker\n",
        "def does_post_follow_rules(tweet):\n",
        "  response = model.generate_content(\n",
        "    \"\"\"Does the post follow the following rules:\n",
        "\n",
        "    1. Keep your posts below 150 characters\n",
        "    2. Include the hashtag #We<3LocalGovernment at the end of every tweet\n",
        "    3. Is a little Snarky\n",
        "\n",
        "    Only return Yes or No\n",
        "\n",
        "    Tweet: {0}\n",
        "    Output: \"\"\".format(tweet)\n",
        "    )\n",
        "  return response.text.strip()\n",
        "\n",
        "# post unit test\n",
        "import unittest\n",
        "\n",
        "class TestPostRules(unittest.TestCase):\n",
        "\n",
        "    def test_post_results_1(self):\n",
        "      generated_post = snarkPost(\"Write a tweet about our Thanksgiving Day Special\")\n",
        "      correct = does_post_follow_rules(generated_post)\n",
        "      self.assertEqual(correct, \"Yes\")\n",
        "\n",
        "    def test_does_not_follow_rules(self):\n",
        "      generated_post = \"This is a run-on sentence, it has no tone to it, it is very long and probabaly written poorly, it also is only about itself and no other category, sometimes it likes to keep typing just to add more space to the sentence it exists as.\"\n",
        "      correct = does_post_follow_rules(generated_post)\n",
        "      self.assertEqual(correct, \"No\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run test\n",
        "postGenerated = snarkPost('Write a post about wild boars')\n",
        "postGenerated_safe = postGenerated.replace(\"'\", \"\\\\'\")\n",
        "print(postGenerated_safe)\n",
        "\n",
        "followedOrders = does_post_follow_rules(postGenerated_safe)\n",
        "print(followedOrders)\n"
      ],
      "metadata": {
        "id": "UOyIx_bwwQuO"
      },
      "id": "UOyIx_bwwQuO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# question classifier\n",
        "def classifyQuestionType(prompt):\n",
        "  response = model.generate_content(\n",
        "    \"\"\"Context: You look at questions and categorize them as\n",
        "    Employment, General Information, Emergency Services, or Tax Related.\n",
        "\n",
        "  Output only Employment, General Information, Emergency Services, or Tax Related\n",
        "\n",
        "  Input: Why are my taxes so high?\n",
        "  Output: Tax Related\n",
        "\n",
        "  Message: {0}.\n",
        "  Output: \"\"\".format(prompt)\n",
        "  )\n",
        "  return response.text.strip()\n",
        "\n",
        "# question unit test\n",
        "import unittest # get needed library\n",
        "\n",
        "class TestCategorization(unittest.TestCase):\n",
        "  def test_getClassification(self):\n",
        "    response = classifyQuestionType(\"Why are my pancakes cold?\")\n",
        "    self.assertEqual(response, \"General Information\")\n",
        "\n",
        "  def test_getClassification2(self):\n",
        "    response = classifyQuestionType(\"Where can I find job postings for train conductors?\")\n",
        "    self.assertEqual(response, \"Employment\")\n",
        "\n",
        "  def test_getClassification3(self):\n",
        "    response = classifyQuestionType(\"Why are my taxes so low?\")\n",
        "    self.assertEqual(response, \"Tax Related\")\n",
        "\n",
        "  def test_getClassification4(self):\n",
        "    response = classifyQuestionType(\"Why am I feeling light-headed and my left arm hurts?\")\n",
        "    self.assertEqual(response, \"Emergency Services\")"
      ],
      "metadata": {
        "id": "kPhJS3tGzhtO"
      },
      "id": "kPhJS3tGzhtO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RUN UNIT TESTS\n",
        "\n",
        "unittest.main(argv=[''], verbosity=2, exit=False)"
      ],
      "metadata": {
        "id": "OvH1KXzZ6qqY"
      },
      "id": "OvH1KXzZ6qqY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#run test\n",
        "print(classifyQuestionType(\"How deep is the Nile River?\"))"
      ],
      "metadata": {
        "id": "wdC5eczczxFh"
      },
      "id": "wdC5eczczxFh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the pandas library\n",
        "import pandas as pd\n",
        "import datetime\n",
        "\n",
        "# !pip install --upgrade google-cloud-aiplatform\n",
        "from google.cloud.aiplatform import init\n",
        "# from google.cloud.aiplatform.evaluation import EvalTask\n",
        "from vertexai.evaluation import EvalTask\n",
        "\n",
        "# evaluation data\n",
        "classify_outputs = [\n",
        "    {\n",
        "        \"question\": \"Why are my pancakes cold?\",\n",
        "        \"classifcaiton\": \"General Information\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"Where can I find job postings for train conductors?\",\n",
        "        \"classifcaiton\": \"Employment\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"Why are my taxes so low?\",\n",
        "        \"classifcaiton\": \"Tax Related\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"Why am I feeling light-headed and my left arm hurts?\",\n",
        "        \"classifcaiton\": \"Emergency Services\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"How do I get a promotion?\",\n",
        "        \"classifcaiton\": \"Employment\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"Can I lower my tax burden by moving money from my 401k into a ROTH IRA?\",\n",
        "        \"classifcaiton\": \"Tax Related\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"Ouch my hand hurts?\",\n",
        "        \"classifcaiton\": \"Emergency Services\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"How deep is the Nile River?\",\n",
        "        \"classifcaiton\": \"General Information\"\n",
        "    }\n",
        "]\n",
        "\n",
        "prompt = \"Context: You look at questions and categorize them as Employment, General Information, Emergency Services, or Tax Related. Output only Employment, General Information, Emergency Services, or Tax Related\"\n",
        "contexts = [str(record) for record in classify_outputs]\n",
        "full_prompts = [prompt + str(record) for record in classify_outputs]\n",
        "\n",
        "\n",
        "# CREATE EVALUATION DATASET\n",
        "eval_dataset = pd.DataFrame(\n",
        "  {\n",
        "    \"content\": full_prompts,\n",
        "    \"instruction\": full_prompts,\n",
        "    \"context\": contexts,\n",
        "    \"prompt\": prompt\n",
        "  }\n",
        ")\n",
        "\n",
        "\n",
        "# CREATE EVALUATION TASK\n",
        "qa_eval_task = EvalTask(\n",
        "  dataset=eval_dataset,\n",
        "  metrics=[\"fulfillment\", \"groundedness\"],\n",
        "  experiment=\"question-classification-generation\",\n",
        ")\n",
        "\n",
        "# Load Gemini 2.5 Pro model\n",
        "model = GenerativeModel(\"projects/qwiklabs-gcp-00-711e7fbdb4c8/locations/us-central1/models/gemini-2.5-pro\")\n",
        "\n",
        "\n",
        "# RUN EVALUATION\n",
        "run_ts = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "result = qa_eval_task.evaluate(\n",
        "    model=model,\n",
        "    experiment_run_name=f\"apartment-listing-gen-{run_ts}\"\n",
        "  )\n",
        "\n",
        "evaluation_results = []\n",
        "evaluation_results.append(result)\n",
        "\n",
        "\n",
        "# DISPLAY RESULTS\n",
        "display_eval_report(((\"Eval Result\", result.summary_metrics, result.metrics_table)))\n"
      ],
      "metadata": {
        "id": "RuKMTm20-ZvH"
      },
      "id": "RuKMTm20-ZvH",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "name": "Challenge 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}